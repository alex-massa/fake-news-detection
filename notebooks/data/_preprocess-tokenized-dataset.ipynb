{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb4fdec-73a0-4686-ac77-bb74dda796a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./../utils/_logger.ipynb\n",
    "%run ./../utils/_preprocess-utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a8c9f4-b243-4a46-8d1c-5f4511103ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08672ff-c992-4856-8550-24803c5eebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_OCCURENCES = 5\n",
    "NO_ABOVE = 1\n",
    "DOCUMENT_FILTERS = (deaccent, lower_to_unicode, strip_tags, strip_multiple_whitespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdcf25d-4a69-430b-b1c7-2e0082c00e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[proc_doc_col] = df[doc_col].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c63d394-fcdd-4107-a06f-85dd1425fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Preprocessing corpus...\")\n",
    "df[proc_doc_col] = [apply_filters(doc, filters=DOCUMENT_FILTERS) for doc in tqdm(df[proc_doc_col], disable=SILENT)]\n",
    "\n",
    "logger.info(\"Replacing special characters...\")\n",
    "df[proc_doc_col] = [sub_pattern(doc, pattern=SUB_PATTERN) for doc in tqdm(df[proc_doc_col], disable=SILENT)]\n",
    "\n",
    "logger.info(\"Removing unprintable characters...\")\n",
    "df[proc_doc_col] = [remove_unprintable(doc) for doc in tqdm(df[proc_doc_col], disable=SILENT)]\n",
    "\n",
    "logger.info(\"Tokenizing corpus...\")\n",
    "tokenizer = English().tokenizer\n",
    "df[proc_doc_col] = [[t.text for t in tokenizer(doc) if not t.is_space] for doc in tqdm(df[proc_doc_col], disable=SILENT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f16a04-7a4f-44bb-9427-b7572b80f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make auxiliary dictionary from processed corpus\n",
    "dictionary = Dictionary(df[proc_doc_col])\n",
    "# filter tokens that appear in few documents from dictionary\n",
    "dictionary.filter_extremes(no_below=MIN_OCCURENCES, no_above=NO_ABOVE, keep_n=None)\n",
    "\n",
    "logger.info(\"Replacing unfrequent tokens in corpus...\")\n",
    "df[proc_doc_col] = [[t if t in dictionary.token2id else REPLACEMENT_TOK for t in doc] for doc in tqdm(df[proc_doc_col], disable=SILENT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0261b38-e567-4f75-b782-1e66a41637d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary from processed and subsampled corpus\n",
    "dictionary = Dictionary(df[proc_doc_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc038e6-eac0-4512-b220-3e2cdf8719ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Saving tokenized dataset to disk...\")\n",
    "df.to_pickle(TOK_DATASET_PATH), dictionary.save(TOK_DICTIONARY_PATH)\n",
    "logger.info(\"Tokenized dataset saved to disk.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

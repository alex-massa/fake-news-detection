{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621669b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./../data/load-dataset.ipynb\n",
    "%run ./../homegrown/basic-neural-network.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea296cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3633a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERS = 100\n",
    "\n",
    "RANDOM_SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f80171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, labels = df[[proc_doc_col, label_col]].T.values\n",
    "X = [np.array(dictionary.doc2bow(doc)) for doc in corpus]\n",
    "y = np.array([np.eye(2)[int(label)] for label in labels])\n",
    "train_samples, test_samples, train_labels, test_labels = train_test_split(X, y, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33dc6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_size = 100\n",
    "iterations = ITERS + 1\n",
    "alpha = 1e-3\n",
    "hid_activation = Activation.RELU\n",
    "out_activation = Activation.SIGMOID\n",
    "dropout = True\n",
    "as_probs = True\n",
    "factor_words_freq = False\n",
    "yield_results = True\n",
    "silent = False\n",
    "random_seed = RANDOM_SEED\n",
    "\n",
    "model = BasicSparseNeuralNetwork(len(dictionary), hidden_layer_size, epochs=iterations, alpha=alpha,\n",
    "                                 hid_activation=hid_activation, out_activation=out_activation, \n",
    "                                 dropout=dropout, as_probs=as_probs,\n",
    "                                 factor_words_freq=factor_words_freq, yield_results=yield_results, \n",
    "                                 silent=silent, random_seed=random_seed)\n",
    "\n",
    "data = []\n",
    "predict_sentiment_gen = model.evaluate(train_samples, test_samples, train_labels, test_labels)\n",
    "for (train_preds, train_errors), (test_preds, test_errors) in predict_sentiment_gen:\n",
    "    train_loss = sum(train_errors) / len(train_samples)\n",
    "    train_correct = sum([np.argmax(pred) == np.argmax(label)\n",
    "                         for pred, label\n",
    "                         in zip(train_preds, train_labels)])\n",
    "    train_accuracy = train_correct / len(train_samples)\n",
    "    \n",
    "    test_loss = sum(test_errors) / len(test_samples)\n",
    "    test_correct = sum([np.argmax(pred) == np.argmax(label)\n",
    "                        for pred, label\n",
    "                        in zip(test_preds, test_labels)])\n",
    "    test_accuracy = test_correct / len(test_samples)\n",
    "    \n",
    "    data.append({'Train Predictions': train_preds, 'Train Errors': train_errors,\n",
    "                 'Train Loss (MSE)': train_loss, 'Train Accuracy': train_accuracy,\n",
    "                 'Test Predictions': test_preds, 'Test Errors': test_errors,\n",
    "                 'Test Loss (MSE)': test_loss, 'Test Accuracy': test_accuracy,\n",
    "                 'Correct (Train)': train_correct, 'Correct (Test)': test_correct})\n",
    "\n",
    "results = pd.DataFrame(data)\n",
    "results[['Train Loss (MSE)', 'Train Accuracy', 'Test Loss (MSE)', 'Test Accuracy']][::10].style \\\n",
    "            .highlight_min(subset=['Train Accuracy', 'Test Accuracy'], color='lightcoral') \\\n",
    "            .highlight_max(subset=['Train Accuracy', 'Test Accuracy'], color='lightgreen') \\\n",
    "            .highlight_min(subset=['Train Loss (MSE)', 'Test Loss (MSE)'], color='lightgreen') \\\n",
    "            .highlight_max(subset=['Train Loss (MSE)', 'Test Loss (MSE)'], color='lightcoral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb10aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = 'true'\n",
    "\n",
    "true_preds, true_labels = [np.argmax(pred) for pred in test_preds], \\\n",
    "                          [np.argmax(label) for label in test_labels]\n",
    "ConfusionMatrixDisplay.from_predictions(true_labels, true_preds, normalize=normalize,\n",
    "                                        cmap=plt.cm.Blues, display_labels=('reliable', 'unreliable'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208e84dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ./../data/load-dataset.ipynb\n",
    "%run ./../word2vec/_load-w2v-model.ipynb\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95440f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9625293",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1f757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=['elysee'], topn=10), \\\n",
    "w2v_model.wv.most_similar(positive=['crimea'], topn=10), \\\n",
    "w2v_model.wv.most_similar(positive=['nagorno'], topn=10), \\\n",
    "w2v_model.wv.most_similar(positive=['milan'], topn=10), \\\n",
    "w2v_model.wv.most_similar(positive=['makeshift'], topn=10), \\\n",
    "w2v_model.wv.most_similar(positive=['rigged'], topn=10), \\\n",
    "w2v_model.wv.most_similar(positive=['zion'], topn=10), \\\n",
    "w2v_model.wv.most_similar(positive=['nord'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e857efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=['johnson'], topn=10), \\\n",
    "w2v_model.wv.most_similar(positive=['jinping'], topn=10), \\\n",
    "w2v_model.wv.most_similar(positive=['macron'], topn=10), \\\n",
    "w2v_model.wv.most_similar(positive=['assad'], topn=10), \\\n",
    "w2v_model.wv.most_similar(positive=['francis'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=['mcconnell', 'schumer'], topn=10), \\\n",
    "w2v_model.wv.most_similar(positive=['occupation', 'liberation'], topn=10), \\\n",
    "w2v_model.wv.most_similar(positive=['lockheed', 'sukhoi', 'dassault'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3736f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.doesnt_match(['italian', 'british', 'european', 'eurofighter']), \\\n",
    "w2v_model.wv.doesnt_match(['train', 'plane', 'museum', 'bus', 'car'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e74a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=['king', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4655d8",
   "metadata": {},
   "source": [
    "Averaging the word embeddings for words contained in a document should yield a vector that approximates a word embedding that \"summarizes\" the content of the document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b09cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_idx = 99\n",
    "doc, proc_doc = df[[doc_col, proc_doc_col]].values[doc_idx]\n",
    "w2v_doc = w2v_model.wv[proc_doc]\n",
    "w2v_model.wv.most_similar(positive=np.mean(w2v_doc, axis=0), topn=5), f\"«{doc[:10000]}…»\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33c2819",
   "metadata": {},
   "source": [
    "Visualize the word embeddings in a given document by reducing them into 2-dimensional arrays in order to plot them on a carthesian 2-dimensional plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c4129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality reduction\n",
    "doc_idx = 12\n",
    "sample_doc = df[proc_doc_col][doc_idx]\n",
    "word_indices = {i: w2v_model.wv.key_to_index[token] for i, token in enumerate(set(sample_doc))}\n",
    "\n",
    "n_labeled = 40\n",
    "random_seed = RANDOM_SEED\n",
    "\n",
    "reduced_wv = TSNE(n_components=3, verbose=True, random_state=random_seed) \\\n",
    "                .fit_transform(w2v_model.wv[sample_doc])\n",
    "x, y, z = reduced_wv.T\n",
    "# label randomly subsampled data points\n",
    "selected_indices = {i: word_indices[i] for i \n",
    "                    in np.random.default_rng(seed=random_seed).choice(np.array(list(word_indices.keys())), n_labeled)}\n",
    "# plot\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(x, y, z)\n",
    "[plt.annotate(w2v_model.wv.index_to_key[idx], (x[i], y[i]), \n",
    "              bbox=dict(boxstyle='round, pad=0.3', fc='w', ec='k', lw=1)) \n",
    " for i, idx in selected_indices.items()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e8c50-5250-4d74-a3ae-20e02563d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./../utils/_logger.ipynb\n",
    "%run ./../utils/_preprocess-utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32237bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be505f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRF_DATA_DIR = f'{PROC_DATA_DIR}/trf'\n",
    "TRF_DATA_PATH = f'{TRF_DATA_DIR}/trf_data.np'\n",
    "\n",
    "TRF_MODEL_NAME = 'distilbert-base-uncased'\n",
    "\n",
    "SAMPLE_LENGTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d082f-f8c5-49cc-9d08-b242dc599189",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENT_FILTERS = (deaccent, lower_to_unicode, strip_tags, strip_multiple_whitespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43bf228-f845-45fc-98ab-9d914c5f0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(TRF_DATA_PATH).is_file():\n",
    "    corpus = df[doc_col].values\n",
    "    tokenizer = AutoTokenizer.from_pretrained(TRF_MODEL_NAME)\n",
    "\n",
    "    logger.info(\"Preprocessing corpus...\")\n",
    "    corpus = [apply_filters(doc, filters=DOCUMENT_FILTERS) for doc in tqdm(corpus, disable=SILENT)]\n",
    "\n",
    "    logger.info(\"Replacing special characters...\")\n",
    "    corpus = [sub_pattern(doc, pattern=SUB_PATTERN) for doc in tqdm(corpus, disable=SILENT)]\n",
    "\n",
    "    logger.info(\"Removing unprintable characters...\")\n",
    "    corpus = [remove_unprintable(doc) for doc in tqdm(corpus, disable=SILENT)]\n",
    "\n",
    "    logger.info(\"Tokenizing corpus...\")\n",
    "    corpus = [tokenizer.encode_plus(doc, max_length=SAMPLE_LENGTH, truncation=True, padding='max_length',\n",
    "                                    add_special_tokens=True, return_attention_mask=True, return_token_type_ids=False)\n",
    "              for doc in tqdm(corpus, disable=SILENT)]\n",
    "\n",
    "    trf_input_ids = [sample['input_ids'] for sample in corpus]\n",
    "    trf_attention_mask = [sample['attention_mask'] for sample in corpus]\n",
    "    trf_data = np.stack((trf_input_ids, trf_attention_mask), axis=1)\n",
    "\n",
    "    logger.info(\"Storing encoded corpus to disk...\")\n",
    "    Path(TRF_DATA_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    with open(TRF_DATA_PATH, 'wb') as f:\n",
    "        np.save(f, trf_data)\n",
    "else:\n",
    "    with open(TRF_DATA_PATH, 'rb') as f:\n",
    "        trf_data = np.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5e8c50-5250-4d74-a3ae-20e02563d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./../utils/_logger.ipynb\n",
    "%run ./../utils/_preprocess-utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32237bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be505f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRF_DATA_DIR = f'{PROC_DATA_DIR}/trf'\n",
    "TRF_DATA_PATH = f'{TRF_DATA_DIR}/trf_data.np'\n",
    "\n",
    "TRF_PREPROCESSOR_HANDLE = 'https://tfhub.dev/tensorflow/albert_en_preprocess/3'\n",
    "TRF_MODEL_HANDLE = 'https://tfhub.dev/tensorflow/albert_en_base/3'\n",
    "USE_TYPE_IDS = True\n",
    "\n",
    "SEQ_LEN = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d082f-f8c5-49cc-9d08-b242dc599189",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENT_FILTERS = (deaccent, lower_to_unicode, strip_tags, strip_multiple_whitespaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6862dd-6748-46e2-9f63-15400083033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(TRF_DATA_PATH).is_file():\n",
    "    corpus = df[doc_col].values\n",
    "\n",
    "    logger.info(\"Preprocessing corpus...\")\n",
    "    corpus = [apply_filters(doc, filters=DOCUMENT_FILTERS) for doc in tqdm(corpus, disable=SILENT)]\n",
    "\n",
    "    logger.info(\"Replacing special characters...\")\n",
    "    corpus = [sub_pattern(doc, pattern=SUB_PATTERN) for doc in tqdm(corpus, disable=SILENT)]\n",
    "\n",
    "    logger.info(\"Removing unprintable characters...\")\n",
    "    corpus = [remove_unprintable(doc) for doc in tqdm(corpus, disable=SILENT)]\n",
    "\n",
    "    logger.info(\"Tokenizing corpus...\")    \n",
    "    preprocessor = hub.load(TRF_PREPROCESSOR_HANDLE)\n",
    "    tokenizer = hub.KerasLayer(preprocessor.tokenize)\n",
    "    inputs_packer = hub.KerasLayer(preprocessor.bert_pack_inputs, arguments=dict(seq_length=SEQ_LEN))\n",
    "    \n",
    "    tokenizer_input = [Input(shape=(), dtype=tf.string)]\n",
    "    tokenizer_output = inputs_packer([tokenizer(doc) for doc in tokenizer_input])\n",
    "    corpus = Model(tokenizer_input, tokenizer_output).predict(tf.constant(corpus), batch_size=8, verbose=not SILENT)\n",
    "\n",
    "    if USE_TYPE_IDS:\n",
    "        trf_data = np.stack((corpus['input_word_ids'], corpus['input_mask'], corpus['input_type_ids']), axis=1)\n",
    "    else:\n",
    "        trf_data = np.stack((corpus['input_word_ids'], corpus['input_mask']), axis=1)\n",
    "\n",
    "    logger.info(\"Storing encoded corpus to disk...\")\n",
    "    Path(TRF_DATA_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    with open(TRF_DATA_PATH, 'wb') as f:\n",
    "        np.save(f, trf_data)\n",
    "else:\n",
    "    with open(TRF_DATA_PATH, 'rb') as f:\n",
    "        trf_data = np.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
